{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_func(x):\n",
    "\n",
    "    L = 1 / (1 + np.exp(-x))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, tol=10 ** -4):\n",
    "\n",
    "    LearningRate = 0.05\n",
    "\n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "    n_sample = X_train.shape[0]\n",
    "\n",
    "    weights = 2 * np.random.random_sample((n_features + 1, 1)) - 1  # random[-1,1)\n",
    "\n",
    "    print(\n",
    "        \"It is normal to see: 'ex1.py:13: RuntimeWarning: overflow encountered in exp'\"\n",
    "    )\n",
    "    print(\"Please wait for a while for traning, sometimes fast, sometimes slow\")\n",
    "    round = 1\n",
    "    while True:\n",
    "        print(f\"The {round}th round\")\n",
    "        # initialize delta\n",
    "        delta = [0 for i in range(0, n_features + 1)]\n",
    "\n",
    "        for t in range(1, n_sample + 1):\n",
    "            g = 0\n",
    "\n",
    "            g = g + weights[0]  # add back w_0\n",
    "\n",
    "            for i in range(1, n_features + 1):\n",
    "\n",
    "                g = g + weights[i] * X_train[t - 1, i - 1]\n",
    "\n",
    "            L = logistic_func(g)\n",
    "\n",
    "            # add delta_0\n",
    "            old_zero = delta[0]\n",
    "            delta[0] = delta[0] + (y_train[t - 1] - L)  # add back delta w_0\n",
    "\n",
    "            for i in range(1, n_features + 1):\n",
    "                old_delta = delta[i]\n",
    "                delta[i] = delta[i] + (y_train[t - 1] - L) * X_train[t - 1, i - 1]\n",
    "\n",
    "        # for storing old weight of each round\n",
    "        old_wieght = np.copy(weights)\n",
    "\n",
    "        for i in range(0, n_features + 1):\n",
    "            weights[i] = weights[i] + LearningRate * delta[i]\n",
    "\n",
    "        # calculation convergence\n",
    "        converge = 0\n",
    "\n",
    "        for t in range(0, n_features + 1):\n",
    "            converge = converge + abs(weights[t] - old_wieght[t])\n",
    "\n",
    "\n",
    "        print(f\"converge value is {converge}\")\n",
    "\n",
    "        if converge < tol:\n",
    "            break\n",
    "        else:\n",
    "            round += 1\n",
    "\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matrix(X_train, y_train, tol=10 ** -4):\n",
    "\n",
    "    print(\n",
    "        \"It is normal to see: 'ex1.py:13: RuntimeWarning: overflow encountered in exp'\"\n",
    "    )\n",
    "    print(\"Please wait for a while for traning, sometimes fast, sometimes slow\")\n",
    "    LearningRate = 0.05\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    weights = 2 * np.random.random_sample((n_features + 1, 1)) - 1  # random[-1,1)\n",
    "\n",
    "    x_train = np.empty((X_train.shape[0], X_train.shape[1] + 1))\n",
    "    # x_train = (750x3)\n",
    "    row = 0\n",
    "    for x in X_train:\n",
    "\n",
    "        x = np.insert(x, 0, 1, axis=0)\n",
    "        x_train[row] = x\n",
    "        row += 1\n",
    "\n",
    "    y_train = np.transpose(np.array([y_train]))\n",
    "\n",
    "    round = 1\n",
    "    while True:\n",
    "        print(f\"The {round}th round\")\n",
    "        old_weights = np.copy(weights)\n",
    "        mul = np.matmul(x_train, weights)\n",
    "        take_logistics = logistic_func(mul)\n",
    "        subtract_log = y_train - take_logistics\n",
    "        delta = np.matmul(np.transpose(x_train), subtract_log)\n",
    "        weights = weights + delta * LearningRate\n",
    "        converge = np.sum(np.absolute(weights - old_weights))\n",
    "\n",
    "        print(f\"converge value is {converge}\")\n",
    "\n",
    "        if converge < tol:\n",
    "            break\n",
    "        else:\n",
    "            round += 1\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, weights):\n",
    "\n",
    "    predictions = []\n",
    "    n_samples = X_test.shape[0]\n",
    "\n",
    "    for i in range(0, n_samples):\n",
    "        prbability = logistic_func(\n",
    "            np.matmul(np.transpose(weights[1:]), X_test[i]) + weights[0]\n",
    "        )\n",
    "        #classification\n",
    "        if prbability > 0.5:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    predictions = np.array(predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(X_test, X_test_prediction):\n",
    "    X_test1 = X_test[X_test_prediction == 0, :]\n",
    "    X_test2 = X_test[X_test_prediction == 1, :]\n",
    "    plt.scatter(X_test1[:, 0], X_test1[:, 1], color=\"red\")\n",
    "    plt.scatter(X_test2[:, 0], X_test2[:, 1], color=\"blue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "n_samples = 1000\n",
    "\n",
    "centers = [(-1, -1), (5, 10)]\n",
    "X, y = make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    n_features=2,\n",
    "    cluster_std=1.8,\n",
    "    centers=centers,\n",
    "    shuffle=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Experiments\n",
    "w = train(X_train, y_train)\n",
    "# w = train_matrix(X_train, y_train)\n",
    "X_test_prediction = predict(X_test, w)\n",
    "plot_prediction(X_test, X_test_prediction)\n",
    "plot_prediction(X_test, y_test)\n",
    "\n",
    "wrong = np.count_nonzero(y_test - X_test_prediction)\n",
    "print(\"Number of wrong predictions is: \" + str(wrong))\n",
    "\n",
    "# np.array([-111.83560223,19.15577369, 16.4830988])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
